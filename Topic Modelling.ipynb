{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aanybody</th>\n",
       "      <th>aapke</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarthi</th>\n",
       "      <th>abalance</th>\n",
       "      <th>abalanced</th>\n",
       "      <th>abarnacle</th>\n",
       "      <th>abassist</th>\n",
       "      <th>abelief</th>\n",
       "      <th>aberration</th>\n",
       "      <th>...</th>\n",
       "      <th>youwhy</th>\n",
       "      <th>youworried</th>\n",
       "      <th>youwould</th>\n",
       "      <th>youyou</th>\n",
       "      <th>yupi</th>\n",
       "      <th>zakir</th>\n",
       "      <th>zameen</th>\n",
       "      <th>zameer</th>\n",
       "      <th>zfg</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>indiatoday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ndtv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>republic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 6298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aanybody  aapke  aaron  aarthi  abalance  abalanced  abarnacle  \\\n",
       "indiatoday         1      0      0       0         1          2          0   \n",
       "ndtv               0      0      0       2         0          0          0   \n",
       "republic           0      1      1       0         1          0          1   \n",
       "\n",
       "            abassist  abelief  aberration  ...  youwhy  youworried  youwould  \\\n",
       "indiatoday         0        0           0  ...       0           0         1   \n",
       "ndtv               0        0           0  ...       1           1         0   \n",
       "republic           1        1           1  ...       0           0         0   \n",
       "\n",
       "            youyou  yupi  zakir  zameen  zameer  zfg  zoom  \n",
       "indiatoday       0     1      0       1       0    0     0  \n",
       "ndtv             2     0      1       0       2    0     0  \n",
       "republic         0     0      0       0       0    1     2  \n",
       "\n",
       "[3 rows x 6298 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indiatoday</th>\n",
       "      <th>ndtv</th>\n",
       "      <th>republic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>aanybody</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aapke</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aaron</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aarthi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abalance</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          indiatoday  ndtv  republic\n",
       "aanybody           1     0         0\n",
       "aapke              0     0         1\n",
       "aaron              0     0         1\n",
       "aarthi             0     2         0\n",
       "abalance           1     0         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.008*\"court\" + 0.005*\"want\" + 0.005*\"know\" + 0.005*\"say\" + 0.005*\"said\" + 0.004*\"im\" + 0.004*\"supreme\" + 0.004*\"come\" + 0.004*\"dont\" + 0.004*\"people\"'),\n",
       " (1,\n",
       "  '0.000*\"know\" + 0.000*\"said\" + 0.000*\"say\" + 0.000*\"today\" + 0.000*\"supreme\" + 0.000*\"want\" + 0.000*\"people\" + 0.000*\"court\" + 0.000*\"im\" + 0.000*\"dont\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"court\" + 0.004*\"think\" + 0.004*\"act\" + 0.004*\"said\" + 0.004*\"given\" + 0.003*\"know\" + 0.003*\"come\" + 0.003*\"supreme\" + 0.003*\"today\" + 0.003*\"muslims\"'),\n",
       " (1,\n",
       "  '0.000*\"court\" + 0.000*\"want\" + 0.000*\"im\" + 0.000*\"know\" + 0.000*\"say\" + 0.000*\"supreme\" + 0.000*\"people\" + 0.000*\"think\" + 0.000*\"today\" + 0.000*\"said\"'),\n",
       " (2,\n",
       "  '0.007*\"court\" + 0.006*\"say\" + 0.006*\"want\" + 0.006*\"know\" + 0.006*\"im\" + 0.005*\"said\" + 0.005*\"dont\" + 0.004*\"supreme\" + 0.004*\"come\" + 0.004*\"people\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"court\" + 0.006*\"want\" + 0.006*\"say\" + 0.005*\"im\" + 0.005*\"said\" + 0.005*\"know\" + 0.005*\"today\" + 0.004*\"come\" + 0.004*\"supreme\" + 0.004*\"dont\"'),\n",
       " (1,\n",
       "  '0.000*\"want\" + 0.000*\"court\" + 0.000*\"know\" + 0.000*\"said\" + 0.000*\"im\" + 0.000*\"say\" + 0.000*\"come\" + 0.000*\"supreme\" + 0.000*\"dont\" + 0.000*\"people\"'),\n",
       " (2,\n",
       "  '0.000*\"court\" + 0.000*\"know\" + 0.000*\"want\" + 0.000*\"supreme\" + 0.000*\"said\" + 0.000*\"say\" + 0.000*\"come\" + 0.000*\"people\" + 0.000*\"im\" + 0.000*\"case\"'),\n",
       " (3,\n",
       "  '0.008*\"court\" + 0.006*\"know\" + 0.005*\"case\" + 0.005*\"say\" + 0.004*\"said\" + 0.004*\"want\" + 0.004*\"okay\" + 0.004*\"party\" + 0.003*\"mean\" + 0.003*\"supreme\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach aint working out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouns Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>indiatoday</td>\n",
       "      <td>the supreme courts our yoga verdict wasdeliver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ndtv</td>\n",
       "      <td>hello and welcome youre watching leftright and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>republic</td>\n",
       "      <td>hello and welcome ladies and gentlementhis is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   transcript\n",
       "indiatoday  the supreme courts our yoga verdict wasdeliver...\n",
       "ndtv        hello and welcome youre watching leftright and...\n",
       "republic    hello and welcome ladies and gentlementhis is ..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = pd.read_pickle('data_clean.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>indiatoday</td>\n",
       "      <td>supreme verdict today judge unanimousverdict b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ndtv</td>\n",
       "      <td>hello youre im father itis case dispute amatte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>republic</td>\n",
       "      <td>hello ladies gentlementhis edition sundaydebat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   transcript\n",
       "indiatoday  supreme verdict today judge unanimousverdict b...\n",
       "ndtv        hello youre im father itis case dispute amatte...\n",
       "republic    hello ladies gentlementhis edition sundaydebat..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns = pd.DataFrame(data_clean.transcript.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "add_stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aanybody</th>\n",
       "      <th>aapke</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarthi</th>\n",
       "      <th>abalance</th>\n",
       "      <th>abarnacle</th>\n",
       "      <th>abassist</th>\n",
       "      <th>abelief</th>\n",
       "      <th>aberration</th>\n",
       "      <th>ability</th>\n",
       "      <th>...</th>\n",
       "      <th>youso</th>\n",
       "      <th>youspread</th>\n",
       "      <th>youuninformative</th>\n",
       "      <th>youve</th>\n",
       "      <th>youwe</th>\n",
       "      <th>youyou</th>\n",
       "      <th>zakir</th>\n",
       "      <th>zameer</th>\n",
       "      <th>zfg</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>indiatoday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ndtv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>republic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aanybody  aapke  aaron  aarthi  abalance  abarnacle  abassist  \\\n",
       "indiatoday         1      0      0       0         1          0         0   \n",
       "ndtv               0      0      0       1         0          0         0   \n",
       "republic           0      1      1       0         1          1         1   \n",
       "\n",
       "            abelief  aberration  ability  ...  youso  youspread  \\\n",
       "indiatoday        0           0        0  ...      0          0   \n",
       "ndtv              0           0        0  ...      0          0   \n",
       "republic          1           1        1  ...      1          1   \n",
       "\n",
       "            youuninformative  youve  youwe  youyou  zakir  zameer  zfg  zoom  \n",
       "indiatoday                 0      1      0       0      0       0    0     0  \n",
       "ndtv                       0      1      1       2      1       2    0     0  \n",
       "republic                   1      3      0       0      0       0    1     2  \n",
       "\n",
       "[3 rows x 3325 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.transcript)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"court\" + 0.006*\"case\" + 0.006*\"people\" + 0.005*\"muslims\" + 0.005*\"land\" + 0.005*\"issue\" + 0.004*\"judgment\" + 0.004*\"today\" + 0.004*\"temple\" + 0.004*\"question\"'),\n",
       " (1,\n",
       "  '0.009*\"court\" + 0.007*\"today\" + 0.007*\"country\" + 0.006*\"people\" + 0.005*\"im\" + 0.005*\"yesterday\" + 0.004*\"thing\" + 0.004*\"judgment\" + 0.004*\"verdict\" + 0.004*\"point\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"court\" + 0.006*\"act\" + 0.006*\"today\" + 0.006*\"judgment\" + 0.006*\"muslims\" + 0.006*\"people\" + 0.005*\"mosque\" + 0.005*\"question\" + 0.005*\"verdict\" + 0.005*\"evidence\"'),\n",
       " (1,\n",
       "  '0.014*\"court\" + 0.008*\"people\" + 0.007*\"case\" + 0.007*\"today\" + 0.006*\"country\" + 0.005*\"im\" + 0.005*\"time\" + 0.005*\"point\" + 0.004*\"judgment\" + 0.004*\"party\"'),\n",
       " (2,\n",
       "  '0.001*\"court\" + 0.000*\"today\" + 0.000*\"people\" + 0.000*\"verdict\" + 0.000*\"case\" + 0.000*\"country\" + 0.000*\"thing\" + 0.000*\"yesterday\" + 0.000*\"judgment\" + 0.000*\"im\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try topics = 3\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"court\" + 0.008*\"today\" + 0.008*\"country\" + 0.008*\"people\" + 0.006*\"im\" + 0.006*\"yesterday\" + 0.005*\"thing\" + 0.005*\"judgment\" + 0.005*\"verdict\" + 0.005*\"point\"'),\n",
       " (1,\n",
       "  '0.001*\"court\" + 0.000*\"people\" + 0.000*\"case\" + 0.000*\"today\" + 0.000*\"im\" + 0.000*\"muslims\" + 0.000*\"verdict\" + 0.000*\"time\" + 0.000*\"day\" + 0.000*\"judgment\"'),\n",
       " (2,\n",
       "  '0.015*\"court\" + 0.007*\"act\" + 0.007*\"today\" + 0.007*\"muslims\" + 0.007*\"judgment\" + 0.006*\"people\" + 0.006*\"mosque\" + 0.005*\"question\" + 0.005*\"verdict\" + 0.005*\"evidence\"'),\n",
       " (3,\n",
       "  '0.016*\"court\" + 0.010*\"case\" + 0.007*\"party\" + 0.006*\"people\" + 0.006*\"temple\" + 0.005*\"land\" + 0.004*\"issue\" + 0.004*\"day\" + 0.004*\"bjp\" + 0.004*\"board\"')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouns And Adjectives Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>indiatoday</td>\n",
       "      <td>supreme yoga verdict today judge unanimousverd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ndtv</td>\n",
       "      <td>hello welcome youre leftright center im father...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>republic</td>\n",
       "      <td>hello welcome ladies gentlementhis live editio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   transcript\n",
       "indiatoday  supreme yoga verdict today judge unanimousverd...\n",
       "ndtv        hello welcome youre leftright center im father...\n",
       "republic    hello welcome ladies gentlementhis live editio..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns_adj = pd.DataFrame(data_clean.transcript.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aanybody</th>\n",
       "      <th>aapke</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarthi</th>\n",
       "      <th>abalance</th>\n",
       "      <th>abalanced</th>\n",
       "      <th>abarnacle</th>\n",
       "      <th>abassist</th>\n",
       "      <th>abelief</th>\n",
       "      <th>aberration</th>\n",
       "      <th>...</th>\n",
       "      <th>youuninformative</th>\n",
       "      <th>youwant</th>\n",
       "      <th>youwe</th>\n",
       "      <th>youyou</th>\n",
       "      <th>yupi</th>\n",
       "      <th>zakir</th>\n",
       "      <th>zameen</th>\n",
       "      <th>zameer</th>\n",
       "      <th>zfg</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>indiatoday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ndtv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>republic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 4183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aanybody  aapke  aaron  aarthi  abalance  abalanced  abarnacle  \\\n",
       "indiatoday         1      0      0       0         1          1          0   \n",
       "ndtv               0      0      0       2         0          0          0   \n",
       "republic           0      1      1       0         1          0          1   \n",
       "\n",
       "            abassist  abelief  aberration  ...  youuninformative  youwant  \\\n",
       "indiatoday         0        0           0  ...                 0        0   \n",
       "ndtv               0        0           0  ...                 0        0   \n",
       "republic           1        1           1  ...                 1        1   \n",
       "\n",
       "            youwe  youyou  yupi  zakir  zameen  zameer  zfg  zoom  \n",
       "indiatoday      0       0     1      0       1       0    0     0  \n",
       "ndtv            1       2     0      1       0       2    0     0  \n",
       "republic        0       0     0      0       0       0    1     2  \n",
       "\n",
       "[3 rows x 4183 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.transcript)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"gandhi\" + 0.002*\"national\" + 0.002*\"media\" + 0.002*\"debate\" + 0.002*\"idea\" + 0.002*\"minute\" + 0.002*\"yeah\" + 0.002*\"lesson\" + 0.002*\"important\" + 0.002*\"kashi\"'),\n",
       " (1,\n",
       "  '0.004*\"party\" + 0.003*\"board\" + 0.002*\"days\" + 0.002*\"relief\" + 0.002*\"mediation\" + 0.002*\"closure\" + 0.002*\"honorable\" + 0.002*\"stakeholders\" + 0.002*\"idea\" + 0.002*\"sunni\"')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"party\" + 0.004*\"board\" + 0.004*\"days\" + 0.003*\"mediation\" + 0.003*\"honorable\" + 0.003*\"stakeholders\" + 0.003*\"sunni\" + 0.002*\"relief\" + 0.002*\"map\" + 0.002*\"arguments\"'),\n",
       " (1,\n",
       "  '0.003*\"idea\" + 0.002*\"gandhi\" + 0.002*\"media\" + 0.002*\"national\" + 0.002*\"debate\" + 0.002*\"closure\" + 0.002*\"minute\" + 0.002*\"kashi\" + 0.002*\"yeah\" + 0.002*\"lesson\"'),\n",
       " (2,\n",
       "  '0.000*\"party\" + 0.000*\"media\" + 0.000*\"debate\" + 0.000*\"gandhi\" + 0.000*\"idea\" + 0.000*\"important\" + 0.000*\"minute\" + 0.000*\"lesson\" + 0.000*\"yeah\" + 0.000*\"national\"')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 3 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"gandhi\" + 0.003*\"debate\" + 0.003*\"media\" + 0.003*\"national\" + 0.003*\"idea\" + 0.003*\"yeah\" + 0.003*\"minute\" + 0.003*\"lesson\" + 0.002*\"important\" + 0.002*\"vadra\"'),\n",
       " (1,\n",
       "  '0.007*\"party\" + 0.004*\"board\" + 0.004*\"days\" + 0.004*\"mediation\" + 0.004*\"honorable\" + 0.003*\"stakeholders\" + 0.003*\"relief\" + 0.003*\"sunni\" + 0.003*\"map\" + 0.002*\"arguments\"'),\n",
       " (2,\n",
       "  '0.004*\"closure\" + 0.004*\"idea\" + 0.003*\"mathura\" + 0.003*\"issues\" + 0.002*\"lives\" + 0.002*\"beginnings\" + 0.002*\"relief\" + 0.002*\"mp\" + 0.002*\"feeling\" + 0.002*\"community\"'),\n",
       " (3,\n",
       "  '0.000*\"party\" + 0.000*\"board\" + 0.000*\"gandhi\" + 0.000*\"closure\" + 0.000*\"media\" + 0.000*\"idea\" + 0.000*\"days\" + 0.000*\"honorable\" + 0.000*\"national\" + 0.000*\"relief\"')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*\"closure\" + 0.003*\"idea\" + 0.002*\"issues\" + 0.002*\"mathura\" + 0.002*\"lives\" + 0.002*\"beginnings\" + 0.001*\"community\" + 0.001*\"relief\" + 0.001*\"feeling\" + 0.001*\"mp\"'),\n",
       " (1,\n",
       "  '0.004*\"party\" + 0.003*\"gandhi\" + 0.002*\"national\" + 0.002*\"media\" + 0.002*\"debate\" + 0.002*\"yeah\" + 0.002*\"important\" + 0.002*\"board\" + 0.002*\"idea\" + 0.002*\"minute\"')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Topics estimated\n",
    "\n",
    "#### 1. Closure of issues, relief among community\n",
    "\n",
    "#### 2. Party Politics and Media revolvind around the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'indiatoday'), (1, 'ndtv'), (1, 'republic')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic 1 - india today\n",
    "#### Topic 2 - ndtv and republic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
